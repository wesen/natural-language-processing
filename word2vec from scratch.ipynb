{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The softmax function\n",
    "\n",
    "The softmax function allows us to transform a vector of real numbers into a probability distribution. Its formula is:\n",
    "\n",
    "$$\n",
    "\\mathrm{softmax}(x, i) = \\frac{e^x_i}{\\sum_{j=1}^{n}{e^x_j}}\n",
    "$$\n",
    "\n",
    "$e^x$ gets huge quickly, and makes us run into numerical limitation. We can show that \n",
    "$$\n",
    "\\mathrm{softmax}(x,i) = \\frac{e^{x_i-c}}{\\sum_{j=1}^{n}{e^{x_j - c}}}\n",
    "$$\n",
    "which allows us to subtract the maximum value of our vector from each element to avoid numerical issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    orig_shape = x.shape\n",
    "    \n",
    "    if len(x.shape) > 1:\n",
    "        # Matrix\n",
    "        c = -np.array([np.max(x, axis=1)]).T\n",
    "        e_x = np.exp(x + c)\n",
    "        _sum = e_x.sum(axis=1)\n",
    "        x = e_x / _sum[:, None]\n",
    "    else:\n",
    "        # Vector\n",
    "        c = -np.max(c)\n",
    "        e_x = np.exp(x + c)\n",
    "        _sum = np.sum(e_x)\n",
    "        x = e_x / sum\n",
    "        \n",
    "    assert x.shape == orig_shape\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When implementing derivative functions, it's quite useful to check intermediate results before going wildly off tangent. An easy way to do this is to compute the numerical gradient, and compare the two values.\n",
    "\n",
    "We use a very simple numerical calculation of the gradient:\n",
    "\n",
    "$$\n",
    "\\mathrm{grad}(f(x)) = \\frac{f(x+h) - f(x-h)}{2h}\n",
    "$$\n",
    "\n",
    "We use [numpy multi-index iteration](https://docs.scipy.org/doc/numpy-1.14.0/reference/arrays.nditer.html#tracking-an-index-or-multi-index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gradient(f, x):\n",
    "    fx, grad = f(x)\n",
    "    h = 1e-4\n",
    "    \n",
    "    # x can be a vector or a matrix, so we want to compute the derivative according to each element.\n",
    "    # This is straight out of the cs224n code.\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        ix = it.multi_index\n",
    "        \n",
    "        x[ix] += h\n",
    "        fx_1, _ = f(x)\n",
    "        x[ix] -= 2 * h\n",
    "        fx_2, _ = f(x)\n",
    "        x[ix] += h\n",
    "        \n",
    "        numgrad = (fx_1 - fx_2) / (2 * h)\n",
    "        \n",
    "        # we can now check the numerical gradient against the computed gradient.\n",
    "        reldiff = abs(numgrad - grad[ix]) / max(1, abs(numgrad), abs(grad[ix]))\n",
    "        if reldiff > 1e-5:\n",
    "            print(\"Gradient check failed at index {}: {} should be {}\".format(ix, grad[ix], numgrad))\n",
    "            return\n",
    "        \n",
    "        it.iternext()\n",
    "    \n",
    "    print(\"Gradients seem to be ok!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the gradient checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients seem to be ok!\n"
     ]
    }
   ],
   "source": [
    "def test_gradient_f(x):\n",
    "    return 2. * x[0], np.ones_like(x) * 2.\n",
    "\n",
    "check_gradient(test_gradient_f, np.array([1.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
